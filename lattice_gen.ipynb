{
 "metadata": {
  "name": "",
  "signature": "sha256:dcba8496fda66c586c633e44136dee8d616fc01f593f1fee973ff1fdb9a15950"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Word Lattice Gen and Traversal\n",
      "\n",
      "##Initial Design (*out-of-date! See the New design in next text/markdown cell*)\n",
      "###Input \n",
      "1. a set of words (unicode string)\n",
      "2. a list of sentences in the form of list/string of characters\n",
      "\n",
      "###Output:\n",
      "~~a representation of word lattice. Current design:~~\n",
      "~~- a **sent_list** to represent the sentence, each index correspond to a char position. sent of *n* char has *n+1* positions~~\n",
      "~~- at each index of sent_list, two lists are kept:~~\n",
      "  - ~~**forward_word_table** a *dict*, key=word_length, value= set of words that *starts* at the index poistion of the sentence that are of length of word_length~~ \uff08turns out that only backward_word_table is needed for the DP/Viterbi search\uff09\n",
      "~~  - **backward_word_table** a *dict*, similar to forward_word_table, except that it records words that *ends* at this position~~\n",
      "~~> - usage scenario: extracting words at specific position and their *word-level* context:at each position x, a word candidate *candy* of length n can found in sent_list[x].forward_word_table[n].~~\n",
      "~~>  Its *left word context* can be found in sent_list[x].backword_word_table[?] and its *right word context* can be found in sent_list[x+n].forward_word_table[?]~~\n",
      "\n",
      "\n",
      "----------------------------\n",
      "##Improved Design (see lattice_build.py)\n",
      "\n",
      "\n",
      "\n",
      "### Input: same\n",
      "\n",
      "### Output:\n",
      "- A representation of the lattice for each sentence **lattic_list**, which is a list of lattice\n",
      "  - A **lattice** is a list of dictionaries. *lattice[i]* denotes all the *word bigram* that ends at the position *i* of the sentence\n",
      "  - the dictionary is called **backward_bigram_table**\n",
      "    - *key*: start_index_of_current_word\n",
      "    - *value*: 4-tuple (start_index_of_previous_word, start_index_of_current_word, previous_word_str, current_word_str)\n",
      "    - a 4-tuple **represents**: previous_word==sent[start_index_of_previous_word:end_index_of_previous_word] and current_word=[ start_index_of_current_word:end_index_of_current_word]\n",
      "    - note: a.index are kept for *search algorithm*, while word str are kept for fast feature generation   b. Python convention, the span means [star: end), c. end_index_of_previous word == start_index_of_current_word; \n",
      "  - another dictionary called **forward_word_table**, each of which is asociated with position *i*, it denotes all the words that *start* from that position\n",
      "    - *key*: end_index_of_current_word\n",
      "    - *value*: current_word (that starts at index i and ends at index end_index_of_current_word)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "# (out-dated! experimental!)function for build word lattice\n",
      "#\n",
      "def lattice_build(word_list, lines_of_sentences):\n",
      "    if not type(word_list) is set:\n",
      "        word_list=set(word_list)\n",
      "    \n",
      "    lattice_list=[]\n",
      "    \n",
      "    for sent in lines_of_sentences:\n",
      "        lattice=[]\n",
      "        print \"\\n\\n------ sent=\",  \" \".join(sent), \"------\"\n",
      "        for i in range(len(sent)):\n",
      "            print '\\n\\n==>position ',i\n",
      "            sent_len=len(sent)\n",
      "            forward_word_table={k:u\"\".join(sent[i:i+k]) for k in range(1,sent_len+1-i) if u\"\".join(sent[i:i+k]) in word_list}\n",
      "            backward_word_table={k:u\"\".join(sent[i-k:i]) for k in range(i+1) if u\"\".join(sent[i-k:i]) in word_list}\n",
      "            lattice.append((forward_word_table, backward_word_table))\n",
      "            \n",
      "            fwd_t, bwd_t=forward_word_table, backward_word_table\n",
      "            print '\\nfwd_t:'\n",
      "            for l in fwd_t:\n",
      "                print l, fwd_t[l]\n",
      "            print '\\nbwd_t:'\n",
      "            for l in bwd_t:\n",
      "                print l, bwd_t[l]\n",
      "            print '===========\\n'        \n",
      "        \n",
      "        lattice_list.append(lattice)\n",
      "    \n",
      "    return lattice_list\n",
      "\n",
      "#we decide that we use sent representation WITHOUT star/end symbol\n",
      "lines_of_sent=[['#START#','a','b','c','a','#END#'], ['a','b','c','a']]  #with and without special symbol for start/end of sentence\n",
      "\n",
      "word_list=['#START#','ab','bca','ca', '#END#']\n",
      "\n",
      "lattice_list=lattice_build(word_list, lines_of_sent)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Search/Decoding based on Viterbi Algorithm\n",
      "\n",
      "##Input & Output\n",
      "### Input\n",
      "- for each sentence, there is a *lattice*, which is tuple of (forward_unigram_lattice, backward_bigram_lattice)\n",
      "  - *forward_unigram_lattice*  keeps forward_word_table for position 0...n-1, where n==len(sent)\n",
      "  - *backward_bigram_lattice*  keeps backward_bigram_table for position 1...n, where n==len(sent)\n",
      "### Output\n",
      "- the \"best\" word sequence that covers the original character sequence.\n",
      "> the scoring is based on the evaluation of word bigrams (or unigrams), with optional one word look-ahead, with regard to utility function.\n",
      "\n",
      "\n",
      "## Algorithm\n",
      "The search incrementally moves from position 0 to n of the sentence. It keeps a ranked list of the **best_seq[i]**, the best word sequence (for e.g. word segmentation) until position *i*, where i=0..n, specifically:\n",
      "\n",
      "- *best_seq[i]=(list_of_word_seq, (start_index_last_word, end_index_last_word), socre_of_the_seq)*\n",
      "  - For simplicity of the algorithm description, we also use the notation *best_seq[i].last_word* = sent[start_index_last_word:end_index_last_word]\n",
      "\n",
      "\n",
      "Since it's a dynamic programming algorithm, it can be described with basis and inductive steps.\n",
      "\n",
      "  ### Basis: *i* = 0\n",
      "best_seq[0]=([#START#], (None, 0), 1)\n",
      "\n",
      "\n",
      "  ### Inductive steps:\n",
      "compute best_seq[i]\n",
      "\n",
      "best_seq[i] = best of each\n",
      "\n",
      "best_seq[i-k].score + score(bigram_of(best_seq[i-k].last_word, sent[i-k:i])) \n",
      "for each k such that: \n",
      "  -  0<k<i\n",
      "  - best_seq[i-k] is non-empty\n",
      "  - for the backward_bigram_table in backward_bigram_lattice[i],  backward_bigram_table[i-k] is an non-emtpy set\n",
      "  - furthermore, this set contains the tuple (start_index_of_previous_word, start_index_of_current_word, previous_word_str, current_word_str) such that:         \n",
      "    1. start_index_of_previous_word==best_seq[i-k].start_index_of_last_word and \n",
      "    2. start_index_of_current_word==i-k (i.e. end_index_of_last_word)\n",
      "\n",
      "> In other words, the last word in best_seq[i-k] much match with the previous_word in a bigram of (last_word, current_word) in the backward_bigram_table that is kept for position *i* (i.e. backward_bigram_lattice[i])\n",
      "\n",
      "\n",
      "  ### Final result:\n",
      "best_seq[n], if non-empty, it contains the best word sequence"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    }
   ],
   "metadata": {}
  }
 ]
}